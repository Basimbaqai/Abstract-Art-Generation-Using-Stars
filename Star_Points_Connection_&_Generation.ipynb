{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjnVyCVyDIJd"
      },
      "source": [
        "# Mounting Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfWwc9draeRj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-MPf-nUDbF5"
      },
      "source": [
        "# Showing sample images from the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AddB_OkMDf7C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set paths to the dataset folders\n",
        "dataset_path = \"/content/drive/MyDrive/Constellation Datasest\"\n",
        "stars_folder = os.path.join(dataset_path, \"stars\")\n",
        "labels_folder = os.path.join(dataset_path, \"labels\")\n",
        "\n",
        "# Get the list of image files in both folders\n",
        "stars_files = sorted([f for f in os.listdir(stars_folder) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "labels_files = sorted([f for f in os.listdir(labels_folder) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "# Check if both folders have images and are matched\n",
        "if len(stars_files) != len(labels_files):\n",
        "    print(\"Warning: Number of images in 'stars' and 'labels' folders do not match!\")\n",
        "\n",
        "# Option to show a limited number of stars\n",
        "num_stars_to_show = int(input(\"Enter the number of star images to display: \"))\n",
        "num_stars_to_show = min(num_stars_to_show, len(stars_files), len(labels_files))\n",
        "\n",
        "# Display images side-by-side\n",
        "for i, (star_file, label_file) in enumerate(zip(stars_files, labels_files)):\n",
        "    if i >= num_stars_to_show:\n",
        "        break\n",
        "\n",
        "    star_path = os.path.join(stars_folder, star_file)\n",
        "    label_path = os.path.join(labels_folder, label_file)\n",
        "\n",
        "    # Load the images\n",
        "    star_image = cv2.imread(star_path)\n",
        "    label_image = cv2.imread(label_path)\n",
        "\n",
        "    # Convert BGR to RGB for proper color display\n",
        "    star_image = cv2.cvtColor(star_image, cv2.COLOR_BGR2RGB)\n",
        "    label_image = cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Plot the images\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Star\")\n",
        "    plt.imshow(star_image)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Label\")\n",
        "    plt.imshow(label_image)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMkDJaVZDQL5"
      },
      "source": [
        "# Connecting Star points Using Nearest Neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFgSkHGuaWnK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Upload an image\n",
        "\n",
        "image_path = \"/content/drive/MyDrive/Constellation Datasest/stars/76.png\"  # Get the uploaded file name\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Threshold the image to find contours\n",
        "_, thresh = cv2.threshold(image, 230, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Find contours\n",
        "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Extract contour centers\n",
        "contour_centers = []\n",
        "for contour in contours:\n",
        "    M = cv2.moments(contour)\n",
        "    if M[\"m00\"] != 0:\n",
        "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "        contour_centers.append((cx, cy))\n",
        "\n",
        "# Convert contour centers to numpy array\n",
        "contour_centers = np.array(contour_centers)\n",
        "\n",
        "# Perform K-Nearest Neighbors to find connections\n",
        "knn = NearestNeighbors(n_neighbors=3)  # 2 includes the point itself\n",
        "knn.fit(contour_centers)\n",
        "connections = knn.kneighbors(contour_centers, return_distance=False)\n",
        "\n",
        "# Create a black image to visualize connections\n",
        "height, width = image.shape\n",
        "black_image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
        "\n",
        "# Draw connections\n",
        "for i, neighbors in enumerate(connections):\n",
        "    point1 = contour_centers[i]\n",
        "    for neighbor_index in neighbors[1:]:  # Skip the first neighbor (itself)\n",
        "        point2 = contour_centers[neighbor_index]\n",
        "        cv2.line(black_image, tuple(point1), tuple(point2), (0, 0, 0), 10)\n",
        "\n",
        "# Display the result\n",
        "cv2_imshow(image)\n",
        "cv2_imshow(black_image)\n",
        "\n",
        "# Save the result\n",
        "cv2.imwrite(\"connections_result.jpg\", black_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opXx7BgWFzOV"
      },
      "source": [
        "# Streamlit Graphical Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxBXFbV-GJr1"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from PIL import Image\n",
        "\n",
        "# Function to process the image\n",
        "def process_image(image_path, threshold_value, n_neighbors):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Threshold the image to find contours\n",
        "    _, thresh = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Extract contour centers\n",
        "    contour_centers = []\n",
        "    for contour in contours:\n",
        "        M = cv2.moments(contour)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "            contour_centers.append((cx, cy))\n",
        "\n",
        "    # Convert contour centers to numpy array\n",
        "    contour_centers = np.array(contour_centers)\n",
        "\n",
        "    # Perform K-Nearest Neighbors to find connections\n",
        "    knn = NearestNeighbors(n_neighbors=n_neighbors)\n",
        "    knn.fit(contour_centers)\n",
        "    connections = knn.kneighbors(contour_centers, return_distance=False)\n",
        "\n",
        "    # Create a black image to visualize connections\n",
        "    height, width = image.shape\n",
        "    black_image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
        "\n",
        "    # Draw connections\n",
        "    for i, neighbors in enumerate(connections):\n",
        "        point1 = contour_centers[i]\n",
        "        for neighbor_index in neighbors[1:]:  # Skip the first neighbor (itself)\n",
        "            point2 = contour_centers[neighbor_index]\n",
        "            cv2.line(black_image, tuple(point1), tuple(point2), (0, 0, 0), 10)\n",
        "\n",
        "    return image, black_image\n",
        "\n",
        "# Streamlit UI\n",
        "def main():\n",
        "    st.title(\"Constellation Finder\")\n",
        "\n",
        "    # File uploader\n",
        "    uploaded_file = st.file_uploader(\"Upload an Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Load the uploaded image\n",
        "        image_path = uploaded_file.name\n",
        "        with open(image_path, \"wb\") as f:\n",
        "            f.write(uploaded_file.getbuffer())\n",
        "\n",
        "        # Threshold slider\n",
        "        threshold_value = st.slider(\"Threshold Value\", min_value=0, max_value=255, value=230, step=1)\n",
        "\n",
        "        # Number of neighbors slider\n",
        "        n_neighbors = st.slider(\"Number of Neighbors\", min_value=2, max_value=10, value=3, step=1)\n",
        "\n",
        "        # Process the image\n",
        "        original_image, processed_image = process_image(image_path, threshold_value, n_neighbors)\n",
        "\n",
        "        # Display the images side by side\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.image(original_image, caption=\"Original Image\", use_column_width=True, channels=\"GRAY\")\n",
        "        with col2:\n",
        "            st.image(processed_image, caption=\"Processed Image\", use_column_width=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCt_SBVQNrfv"
      },
      "outputs": [],
      "source": [
        "!streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract Art Image Generation"
      ],
      "metadata": {
        "id": "UuoD0xvI-UfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Step 1: Load Skeleton Image\n",
        "input_image_path = \"/content/connections_result.jpg\"  # Replace with your skeleton\n",
        "input_image = Image.open(input_image_path).convert(\"RGB\")\n",
        "input_image = input_image.resize((512, 512))  # Resize for the model\n",
        "\n",
        "# Step 2: Convert Skeleton to a Conditional Image (Edges)\n",
        "skeleton_np = np.array(input_image)\n",
        "edges = cv2.Canny(skeleton_np, 100, 200)  # Edge detection\n",
        "edges_img = Image.fromarray(edges)\n",
        "\n",
        "# Step 3: Load Pretrained ControlNet and Stable Diffusion\n",
        "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/control_v11p_sd15_canny\", torch_dtype=torch.float16)\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16)\n",
        "pipe.to(\"cuda\")  #Use GPU for faster processing\n",
        "\n",
        "# Step 4: Generate the Output Based on the Skeleton\n",
        "prompt = \"abstract art\"\n",
        "output = pipe(prompt, image=edges_img, num_inference_steps=50).images[0]\n",
        "\n",
        "# Step 5: Save or Display the Result\n",
        "output.save(\"output.png\")\n",
        "output.show()"
      ],
      "metadata": {
        "id": "daWWcDDR-ZnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}