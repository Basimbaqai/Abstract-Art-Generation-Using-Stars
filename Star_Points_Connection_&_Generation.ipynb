{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjnVyCVyDIJd"
   },
   "source": [
    "# Mounting Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfWwc9draeRj"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-MPf-nUDbF5"
   },
   "source": [
    "# Showing sample images from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AddB_OkMDf7C"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths to the dataset folders\n",
    "dataset_path = \"/content/drive/MyDrive/Constellation Datasest\"\n",
    "stars_folder = os.path.join(dataset_path, \"stars\")\n",
    "labels_folder = os.path.join(dataset_path, \"labels\")\n",
    "\n",
    "# Get the list of image files in both folders\n",
    "stars_files = sorted([f for f in os.listdir(stars_folder) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "labels_files = sorted([f for f in os.listdir(labels_folder) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "\n",
    "if len(stars_files) != len(labels_files):\n",
    "    print(\"Warning: Number of images in 'stars' and 'labels' folders do not match!\")\n",
    "\n",
    "num_stars_to_show = int(input(\"Enter the number of star images to display: \"))\n",
    "num_stars_to_show = min(num_stars_to_show, len(stars_files), len(labels_files))\n",
    "\n",
    "for i, (star_file, label_file) in enumerate(zip(stars_files, labels_files)):\n",
    "    if i >= num_stars_to_show:\n",
    "        break\n",
    "\n",
    "    star_path = os.path.join(stars_folder, star_file)\n",
    "    label_path = os.path.join(labels_folder, label_file)\n",
    "\n",
    "    star_image = cv2.imread(star_path)\n",
    "    label_image = cv2.imread(label_path)\n",
    "\n",
    "    star_image = cv2.cvtColor(star_image, cv2.COLOR_BGR2RGB)\n",
    "    label_image = cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Star\")\n",
    "    plt.imshow(star_image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Label\")\n",
    "    plt.imshow(label_image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMkDJaVZDQL5"
   },
   "source": [
    "# Connecting Star points Using Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFgSkHGuaWnK"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Upload an image\n",
    "\n",
    "image_path = \"/content/drive/MyDrive/Constellation Datasest/stars/76.png\"  # Get the uploaded file name\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "_, thresh = cv2.threshold(image, 230, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Extract contour centers\n",
    "contour_centers = []\n",
    "for contour in contours:\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "        contour_centers.append((cx, cy))\n",
    "\n",
    "contour_centers = np.array(contour_centers)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=3)  # 2 includes the point itself\n",
    "knn.fit(contour_centers)\n",
    "connections = knn.kneighbors(contour_centers, return_distance=False)\n",
    "\n",
    "height, width = image.shape\n",
    "black_image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Draw connections\n",
    "for i, neighbors in enumerate(connections):\n",
    "    point1 = contour_centers[i]\n",
    "    for neighbor_index in neighbors[1:]:  # Skip the first neighbor (itself)\n",
    "        point2 = contour_centers[neighbor_index]\n",
    "        cv2.line(black_image, tuple(point1), tuple(point2), (0, 0, 0), 10)\n",
    "\n",
    "cv2_imshow(image)\n",
    "cv2_imshow(black_image)\n",
    "\n",
    "cv2.imwrite(\"connections_result.jpg\", black_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opXx7BgWFzOV"
   },
   "source": [
    "# Streamlit Graphical Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxBXFbV-GJr1"
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def process_image(image_path, threshold_value, n_neighbors):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    _, thresh = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contour_centers = []\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "            contour_centers.append((cx, cy))\n",
    "\n",
    "    contour_centers = np.array(contour_centers)\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    knn.fit(contour_centers)\n",
    "    connections = knn.kneighbors(contour_centers, return_distance=False)\n",
    "\n",
    "    height, width = image.shape\n",
    "    black_image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    for i, neighbors in enumerate(connections):\n",
    "        point1 = contour_centers[i]\n",
    "        for neighbor_index in neighbors[1:]:  # Skip the first neighbor (itself)\n",
    "            point2 = contour_centers[neighbor_index]\n",
    "            cv2.line(black_image, tuple(point1), tuple(point2), (0, 0, 0), 10)\n",
    "\n",
    "    return image, black_image\n",
    "\n",
    "\n",
    "# Streamlit UI\n",
    "def main():\n",
    "    st.title(\"Constellation Finder\")\n",
    "\n",
    "    # File uploader\n",
    "    uploaded_file = st.file_uploader(\"Upload an Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        # Load the uploaded image\n",
    "        image_path = uploaded_file.name\n",
    "        with open(image_path, \"wb\") as f:\n",
    "            f.write(uploaded_file.getbuffer())\n",
    "\n",
    "        # Threshold slider\n",
    "        threshold_value = st.slider(\"Threshold Value\", min_value=0, max_value=255, value=230, step=1)\n",
    "\n",
    "        # Number of neighbors slider\n",
    "        n_neighbors = st.slider(\"Number of Neighbors\", min_value=2, max_value=10, value=3, step=1)\n",
    "\n",
    "        original_image, processed_image = process_image(image_path, threshold_value, n_neighbors)\n",
    "\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            st.image(original_image, caption=\"Original Image\", use_column_width=True, channels=\"GRAY\")\n",
    "        with col2:\n",
    "            st.image(processed_image, caption=\"Processed Image\", use_column_width=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCt_SBVQNrfv"
   },
   "outputs": [],
   "source": [
    "!streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Abstract Art Image Generation"
   ],
   "metadata": {
    "id": "UuoD0xvI-UfG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "input_image_path = \"/content/connections_result.jpg\"\n",
    "input_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "input_image = input_image.resize((512, 512))  # Resize for the model\n",
    "\n",
    "skeleton_np = np.array(input_image)\n",
    "edges = cv2.Canny(skeleton_np, 100, 200)  # Edge detection\n",
    "edges_img = Image.fromarray(edges)\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/control_v11p_sd15_canny\", torch_dtype=torch.float16)\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", controlnet=controlnet,\n",
    "                                                         torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"abstract art\"\n",
    "output = pipe(prompt, image=edges_img, num_inference_steps=50).images[0]\n",
    "\n",
    "output.save(\"output.png\")\n",
    "output.show()"
   ],
   "metadata": {
    "id": "daWWcDDR-ZnK"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
